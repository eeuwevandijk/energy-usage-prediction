{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EnergyUsagePrediction.feature_eng.asum.v1_0_8.ipynb</b>\n",
    "<br/>For my use case \"Energy usage prediction based on historical weather and energy usage data.\". The original dataset  can be downloaded from <a href=\"https://www.kaggle.com/taranvee/smart-home-dataset-with-weather-information\">kaggle</a>\n",
    "<br/>The dataset used in this step (feature engineering) has already been transformed in the ETL step.\n",
    "<br/>Data exploration is described/performed in \"EnergyUsagePrediction.data_exp.asum.1_0_5.Ipynb\"\n",
    "<br/>ETL is described/performed in \"EnergyUsagePrediction.etl.asum.1_0_8.Ipynb\"\n",
    "<br/>\n",
    "<br/>This task transforms input columns of various relations into additional columns to improve model performance. \n",
    "<br/>A subset of those features can be created in an initial task (for example, one-hot encoding of categorical variables or normalization of numerical variables).\n",
    "<br/>Some others require business understanding or multiple iterations to be considered. \n",
    "<br/>This task is one of those benefiting the most from the highly iterative nature of this method.\n",
    "<br/>\n",
    "<br/>In this task I will normalize the data columns in order to be easier to use by machine learning algorithms\n",
    "<br/>I will apply one hot encoding to enum like text columns (columns with just a few text items which indicate a category/type/state)\n",
    "<br/>Additional features will be added like: day of year, minute of day. \n",
    "<br/>Load <i>smart-home-dataset-with-weather-information_filtered.csv</i> file into pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "client_x = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='[credentials]',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_x.get_object(Bucket='xyz',Key='smart-home-dataset-with-weather-information_post_etl.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df = pd.read_csv(body)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For usability we define constants for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 int64\n",
       "Timestamp                  int64\n",
       "TotalUsage_kW            float64\n",
       "Generated_kW             float64\n",
       "HouseOverall_kW          float64\n",
       "DishWasher_kW            float64\n",
       "Furnace1_kW              float64\n",
       "Furnace2_kW              float64\n",
       "HomeOffice_kW            float64\n",
       "Fridge_kW                float64\n",
       "WineCellar_kW            float64\n",
       "GarageDoor_kW            float64\n",
       "KitchenDevice12_kW       float64\n",
       "KitchenDevice14_kW       float64\n",
       "KitchenDevice38_kW       float64\n",
       "Barn_kW                  float64\n",
       "Well_kW                  float64\n",
       "Microwave_kW             float64\n",
       "Living room_kW           float64\n",
       "Solar_kW                 float64\n",
       "Temperature_F            float64\n",
       "WeatherIndicator          object\n",
       "Humidity                 float64\n",
       "Visibility               float64\n",
       "WeatherSummary            object\n",
       "ApparentTemperature_F    float64\n",
       "Pressure_hPa             float64\n",
       "WindSpeed                float64\n",
       "cloudCover                object\n",
       "WindBearing                int64\n",
       "PrecipIntensity          float64\n",
       "dewPoint_F               float64\n",
       "PrecipProbability        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbTimestamp = 'Timestamp'\n",
    "lbTotalEneryUsage = 'TotalUsage_kW'\n",
    "lbEneryGeneration = 'Generated_kW'\n",
    "lbEneryUsageHouseOverall = 'HouseOverall_kW'\n",
    "lbDishwasherUsage = 'DishWasher_kW'\n",
    "lbFurnace1Usage = 'Furnace1_kW'\n",
    "lbFurnace2Usage = 'Furnace2_kW'\n",
    "lbHomeOfficeUsage = 'HomeOffice_kW'\n",
    "lbFridgeUsage = 'Fridge_kW'\n",
    "lbWineUsage = 'WineCellar_kW'\n",
    "lbGarageDoorUsage = 'GarageDoor_kW'\n",
    "lbKitchen12Usage = 'KitchenDevice12_kW'\n",
    "lbKitchen14Usage = 'KitchenDevice14_kW'\n",
    "lbKitchen38Usage = 'KitchenDevice38_kW'\n",
    "lbBarnUsage = 'Barn_kW'\n",
    "lbWellUsage = 'Well_kW'\n",
    "lbMicrowaveUsage = 'Microwave_kW'\n",
    "lbLivingRoomUsage = 'Living room_kW'\n",
    "lbSolarGenerated = 'Solar_kW'\n",
    "lbTemperature = 'Temperature_F'\n",
    "\n",
    "#Textial weather indicators: clear-day, clear-night, cloudy, fog, partly-cloudy-day, partly-cloudy-night, rain, snow, wind\n",
    "lbWeatherIndicator = 'WeatherIndicator'\n",
    "\n",
    "#Humidity range [0,1]\n",
    "lbHumidity = 'Humidity'\n",
    "\n",
    "#Visibility range [0,10]\n",
    "lbVisibility = 'Visibility'\n",
    "\n",
    "#WeatherSummary: Breezy, Breezy and mostly cloudy, clear, drizzle, dry , flurries, flurries and breezy, foggy, heavy snow, light rain, light snow, mostly cloudy, overcast, partly cloudy, rain, rain and breezy, snow\n",
    "lbWeatherSummary = 'WeatherSummary'\n",
    "\n",
    "lbApparentTemperature = 'ApparentTemperature_F'\n",
    "lbPressure = 'Pressure_hPa'\n",
    "lbWindSpeed = 'WindSpeed'\n",
    "lbCloudCover = 'cloudCover'\n",
    "\n",
    "lbWindBearing = 'WindBearing'\n",
    "\n",
    "#average intensity of rain fall: could be mm/minute mm/hour, inch per hour, inch per minute\n",
    "lbPrecipIntensity = 'PrecipIntensity' \t\n",
    "\n",
    "lbDewPoint = 'dewPoint_F'\n",
    "\n",
    "# chance of rain\n",
    "lbPrecipProbability = 'PrecipProbability'\n",
    "\n",
    "lbDayOfYear='dayOfYear'\n",
    "lbHourOfDay='hourOfDay'\n",
    "lbMinuteOfDay='minuteOfDay'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get rid of the small amount of text values in cloudCover, we replace the content with the median value of cloudCover\n",
    "Furthermore, some values are floats as text, and others floats as floats. We are going to change the type float too\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 0.12\n"
     ]
    }
   ],
   "source": [
    "filtered = df[lbCloudCover]\n",
    "median =  (df[filtered != 'cloudCover'])[lbCloudCover].median()\n",
    "print('median: ' + str(median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[lbCloudCover].replace('cloudCover', median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now change the type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[lbCloudCover] = df[lbCloudCover].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12, 0.75, 0.  , 1.  , 0.31, 0.44, 0.13, 0.19, 0.25, 0.16, 0.21,\n",
       "       0.15, 0.14, 0.27, 0.28, 0.17, 0.05, 0.1 , 0.26, 0.29, 0.11, 0.09,\n",
       "       0.06, 0.02, 0.08, 0.04, 0.35, 0.22, 0.23, 0.54, 0.39, 0.03, 0.07,\n",
       "       0.76, 0.62, 0.18, 0.79, 0.48, 0.24, 0.57, 0.41, 0.78, 0.2 , 0.77,\n",
       "       0.46, 0.55, 0.01, 0.51, 0.47, 0.5 , 0.4 , 0.3 , 0.43, 0.33, 0.6 ,\n",
       "       0.68, 0.66, 0.45, 0.34, 0.52, 0.67, 0.49, 0.37, 0.36, 0.61, 0.38,\n",
       "       0.42, 0.53, 0.63, 0.32, 0.56, 0.58, 0.72, 0.73, 0.71, 0.64, 0.59])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[lbCloudCover].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert the two text columns to one hot endoded columns\n",
    "We can use pandas get_dummies method to create one hot encoded columns with a prefix.\n",
    "We start with 'WeatherIndicator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['clear-night', 'partly-cloudy-night', 'clear-day', 'cloudy',\n",
       "       'partly-cloudy-day', 'rain', 'snow', 'wind', 'fog'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[lbWeatherIndicator].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df[lbWeatherIndicator], prefix='weatherIndicator')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now drop the original column (you don't need it anymore)\n",
    "df.drop([lbWeatherIndicator],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for 'WeatherSummary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clear', 'Mostly Cloudy', 'Overcast', 'Partly Cloudy', 'Drizzle',\n",
       "       'Light Rain', 'Rain', 'Light Snow', 'Flurries', 'Breezy', 'Snow',\n",
       "       'Rain and Breezy', 'Foggy', 'Breezy and Mostly Cloudy',\n",
       "       'Breezy and Partly Cloudy', 'Flurries and Breezy', 'Dry',\n",
       "       'Heavy Snow'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[lbWeatherSummary].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df[lbWeatherSummary], prefix='weatherSummary')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now drop the original column (you don't need it anymore)\n",
    "df.drop([lbWeatherSummary],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now all our data types are either type int or type float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                   int64\n",
       "Timestamp                                    int64\n",
       "TotalUsage_kW                              float64\n",
       "Generated_kW                               float64\n",
       "HouseOverall_kW                            float64\n",
       "DishWasher_kW                              float64\n",
       "Furnace1_kW                                float64\n",
       "Furnace2_kW                                float64\n",
       "HomeOffice_kW                              float64\n",
       "Fridge_kW                                  float64\n",
       "WineCellar_kW                              float64\n",
       "GarageDoor_kW                              float64\n",
       "KitchenDevice12_kW                         float64\n",
       "KitchenDevice14_kW                         float64\n",
       "KitchenDevice38_kW                         float64\n",
       "Barn_kW                                    float64\n",
       "Well_kW                                    float64\n",
       "Microwave_kW                               float64\n",
       "Living room_kW                             float64\n",
       "Solar_kW                                   float64\n",
       "Temperature_F                              float64\n",
       "Humidity                                   float64\n",
       "Visibility                                 float64\n",
       "ApparentTemperature_F                      float64\n",
       "Pressure_hPa                               float64\n",
       "WindSpeed                                  float64\n",
       "cloudCover                                 float64\n",
       "WindBearing                                  int64\n",
       "PrecipIntensity                            float64\n",
       "dewPoint_F                                 float64\n",
       "PrecipProbability                          float64\n",
       "weatherIndicator_clear-day                   uint8\n",
       "weatherIndicator_clear-night                 uint8\n",
       "weatherIndicator_cloudy                      uint8\n",
       "weatherIndicator_fog                         uint8\n",
       "weatherIndicator_partly-cloudy-day           uint8\n",
       "weatherIndicator_partly-cloudy-night         uint8\n",
       "weatherIndicator_rain                        uint8\n",
       "weatherIndicator_snow                        uint8\n",
       "weatherIndicator_wind                        uint8\n",
       "weatherSummary_Breezy                        uint8\n",
       "weatherSummary_Breezy and Mostly Cloudy      uint8\n",
       "weatherSummary_Breezy and Partly Cloudy      uint8\n",
       "weatherSummary_Clear                         uint8\n",
       "weatherSummary_Drizzle                       uint8\n",
       "weatherSummary_Dry                           uint8\n",
       "weatherSummary_Flurries                      uint8\n",
       "weatherSummary_Flurries and Breezy           uint8\n",
       "weatherSummary_Foggy                         uint8\n",
       "weatherSummary_Heavy Snow                    uint8\n",
       "weatherSummary_Light Rain                    uint8\n",
       "weatherSummary_Light Snow                    uint8\n",
       "weatherSummary_Mostly Cloudy                 uint8\n",
       "weatherSummary_Overcast                      uint8\n",
       "weatherSummary_Partly Cloudy                 uint8\n",
       "weatherSummary_Rain                          uint8\n",
       "weatherSummary_Rain and Breezy               uint8\n",
       "weatherSummary_Snow                          uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in part I, we need to convert the timesamp int value to proper 1 minute step values\n",
    "The first item starts at '2016-01-01 05:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01 05:00:00\n",
      "2016-12-16 03:29:00\n"
     ]
    }
   ],
   "source": [
    "df[lbTimestamp] = pd.DatetimeIndex(pd.date_range('2016-01-01 05:00', periods=len(df),  freq='min'))\n",
    "print(df[lbTimestamp].min())\n",
    "print(df[lbTimestamp].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create new features dayOfYear, hourOfDay and minuteOfDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[lbDayOfYear] = df[lbTimestamp].apply(lambda x : x.dayofyear)\n",
    "df[lbHourOfDay] = df[lbTimestamp].apply(lambda x : x.hour)\n",
    "df[lbMinuteOfDay] = df[lbTimestamp].apply(lambda x : x.minute + 60*x.hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day of year examples:1,21\n",
      "hour of day examples:5,13\n",
      "minute of day examples:303,785\n"
     ]
    }
   ],
   "source": [
    "print('day of year examples:' + str(df[lbDayOfYear].iloc[0+3])+ ','+ str(df[lbDayOfYear].iloc[20 * 1440+ 8*60 + 5]))\n",
    "print('hour of day examples:' + str(df[lbHourOfDay].iloc[0+3])+ ','+ str(df[lbHourOfDay].iloc[20 * 1440 + 8*60 + 5]))\n",
    "print('minute of day examples:' + str(df[lbMinuteOfDay].iloc[0+3])+ ','+ str(df[lbMinuteOfDay].iloc[20 * 1440 + 8*60 + 5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierFilter = 2\n",
    "#median = float(df[lbTotalEneryUsage].median())\n",
    "\n",
    "df[lbTotalEneryUsage] = np.where(df[lbTotalEneryUsage] > outlierFilter, outlierFilter, df[lbTotalEneryUsage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[lbTotalEneryUsage].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierFilter = 16\n",
    "df[lbWindSpeed] = np.where(df[lbWindSpeed] > outlierFilter, outlierFilter, df[lbWindSpeed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[lbWindSpeed].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlierFilterMax = 1030\n",
    "outlierFilterMin = 1000\n",
    "df[lbPressure] = np.where(df[lbPressure] > outlierFilterMax, outlierFilterMax, df[lbPressure])\n",
    "df[lbPressure] = np.where(df[lbPressure] < outlierFilterMin, outlierFilterMin, df[lbPressure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030.0\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "print(str(df[lbPressure].max()))\n",
    "print(str(df[lbPressure].min()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create normalized columns of our features of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Create a minimum and maximum processor object\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[lbTemperature]].values.astype(float)\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Run the normalizer on the dataframe\n",
    "df[lbTemperature+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbWindSpeed]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbWindSpeed+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbHumidity]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbHumidity+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbPressure]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbPressure+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbCloudCover]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbCloudCover+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbWindBearing]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbWindBearing+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbPrecipIntensity]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbPrecipIntensity+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbDewPoint]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbDewPoint+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbDayOfYear]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbDayOfYear+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbHourOfDay]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbHourOfDay+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = df[[lbMinuteOfDay]].values.astype(float)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[lbMinuteOfDay+'_normalized'] = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                             int64\n",
      "Timestamp                     datetime64[ns]\n",
      "TotalUsage_kW                        float64\n",
      "Generated_kW                         float64\n",
      "HouseOverall_kW                      float64\n",
      "DishWasher_kW                        float64\n",
      "Furnace1_kW                          float64\n",
      "Furnace2_kW                          float64\n",
      "HomeOffice_kW                        float64\n",
      "Fridge_kW                            float64\n",
      "WineCellar_kW                        float64\n",
      "GarageDoor_kW                        float64\n",
      "KitchenDevice12_kW                   float64\n",
      "KitchenDevice14_kW                   float64\n",
      "KitchenDevice38_kW                   float64\n",
      "Barn_kW                              float64\n",
      "Well_kW                              float64\n",
      "Microwave_kW                         float64\n",
      "Living room_kW                       float64\n",
      "Solar_kW                             float64\n",
      "Temperature_F                        float64\n",
      "Humidity                             float64\n",
      "Visibility                           float64\n",
      "ApparentTemperature_F                float64\n",
      "Pressure_hPa                         float64\n",
      "WindSpeed                            float64\n",
      "cloudCover                           float64\n",
      "WindBearing                            int64\n",
      "PrecipIntensity                      float64\n",
      "dewPoint_F                           float64\n",
      "PrecipProbability                    float64\n",
      "weatherIndicator_clear-day             uint8\n",
      "dtype: object\n",
      "weatherIndicator_clear-night                 uint8\n",
      "weatherIndicator_cloudy                      uint8\n",
      "weatherIndicator_fog                         uint8\n",
      "weatherIndicator_partly-cloudy-day           uint8\n",
      "weatherIndicator_partly-cloudy-night         uint8\n",
      "weatherIndicator_rain                        uint8\n",
      "weatherIndicator_snow                        uint8\n",
      "weatherIndicator_wind                        uint8\n",
      "weatherSummary_Breezy                        uint8\n",
      "weatherSummary_Breezy and Mostly Cloudy      uint8\n",
      "weatherSummary_Breezy and Partly Cloudy      uint8\n",
      "weatherSummary_Clear                         uint8\n",
      "weatherSummary_Drizzle                       uint8\n",
      "weatherSummary_Dry                           uint8\n",
      "weatherSummary_Flurries                      uint8\n",
      "weatherSummary_Flurries and Breezy           uint8\n",
      "weatherSummary_Foggy                         uint8\n",
      "weatherSummary_Heavy Snow                    uint8\n",
      "weatherSummary_Light Rain                    uint8\n",
      "weatherSummary_Light Snow                    uint8\n",
      "weatherSummary_Mostly Cloudy                 uint8\n",
      "weatherSummary_Overcast                      uint8\n",
      "weatherSummary_Partly Cloudy                 uint8\n",
      "weatherSummary_Rain                          uint8\n",
      "weatherSummary_Rain and Breezy               uint8\n",
      "weatherSummary_Snow                          uint8\n",
      "dayOfYear                                    int64\n",
      "hourOfDay                                    int64\n",
      "minuteOfDay                                  int64\n",
      "Temperature_F_normalized                   float64\n",
      "WindSpeed_normalized                       float64\n",
      "Humidity_normalized                        float64\n",
      "Pressure_hPa_normalized                    float64\n",
      "cloudCover_normalized                      float64\n",
      "WindBearing_normalized                     float64\n",
      "PrecipIntensity_normalized                 float64\n",
      "dewPoint_F_normalized                      float64\n",
      "dayOfYear_normalized                       float64\n",
      "hourOfDay_normalized                       float64\n",
      "minuteOfDay_normalized                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes[0:32])\n",
    "print(df.dtypes[32:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets save our post ETL dataset to a new csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "project = Project(None,\"[GUID]\",\"p-[GUID]\")\n",
    "project.save_data(file_name = \"smart-home-dataset-with-weather-information_post_feature_eng.csv\",data = df.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now extracted transformed and loaded our data. We can now continue with feature creation in part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
